{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0494caa8-aab6-4c2b-9157-faea627959f1",
   "metadata": {},
   "source": [
    "### Load data from DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "199189a3-397f-423c-90c5-9efdca1ace32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to: C:\\Users\\sarfo\\Dropbox\\Courses\\Data Science\\30-days-of-data-science\\Day-1\\data\\warehouse\\day1.duckdb\n",
      "df shape: (101766, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>label</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>change</th>\n",
       "      <th>insulin</th>\n",
       "      <th>A1Cresult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2278392</td>\n",
       "      <td>8222157</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149190</td>\n",
       "      <td>55629189</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Up</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64410</td>\n",
       "      <td>86047875</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500364</td>\n",
       "      <td>82442376</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Up</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16680</td>\n",
       "      <td>42519267</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Steady</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  person_id  label  time_in_hospital  num_lab_procedures  \\\n",
       "0       2278392    8222157      0                 1                  41   \n",
       "1        149190   55629189      0                 3                  59   \n",
       "2         64410   86047875      0                 2                  11   \n",
       "3        500364   82442376      0                 2                  44   \n",
       "4         16680   42519267      0                 1                  51   \n",
       "\n",
       "   num_procedures  num_medications  number_outpatient  number_emergency  \\\n",
       "0               0                1                  0                 0   \n",
       "1               0               18                  0                 0   \n",
       "2               5               13                  2                 0   \n",
       "3               1               16                  0                 0   \n",
       "4               0                8                  0                 0   \n",
       "\n",
       "   number_inpatient             race  gender      age admission_type_id  \\\n",
       "0                 0        Caucasian  Female   [0-10)                 6   \n",
       "1                 0        Caucasian  Female  [10-20)                 1   \n",
       "2                 1  AfricanAmerican  Female  [20-30)                 1   \n",
       "3                 0        Caucasian    Male  [30-40)                 1   \n",
       "4                 0        Caucasian    Male  [40-50)                 1   \n",
       "\n",
       "  discharge_disposition_id admission_source_id diabetesMed change insulin  \\\n",
       "0                       25                   1          No     No      No   \n",
       "1                        1                   7         Yes     Ch      Up   \n",
       "2                        1                   7         Yes     No      No   \n",
       "3                        1                   7         Yes     Ch      Up   \n",
       "4                        1                   7         Yes     Ch  Steady   \n",
       "\n",
       "  A1Cresult  \n",
       "0      None  \n",
       "1      None  \n",
       "2      None  \n",
       "3      None  \n",
       "4      None  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "project_root = Path.cwd().resolve()\n",
    "while not (project_root / \"Day-1\").exists():\n",
    "    if project_root == project_root.parent:\n",
    "        raise FileNotFoundError(\"Could not find project root containing Day-1.\")\n",
    "    project_root = project_root.parent\n",
    "\n",
    "db_path = project_root / \"Day-1\" / \"data\" / \"warehouse\" / \"day1.duckdb\"\n",
    "con = duckdb.connect(str(db_path))\n",
    "print(\"Connected to:\", db_path)\n",
    "\n",
    "df = con.execute(\"SELECT * FROM gold_diabetes_features_v1\").df()\n",
    "print(\"df shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c46485c-39b9-4387-a5d5-24dac5dedbf7",
   "metadata": {},
   "source": [
    "### Leakage-safe split (same as Day 4–6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db89c7f-0170-4806-8315-f94dedf2d0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid/Test: 60988 20625 20153\n",
      "Prevalence train/valid/test: 0.11218600380402702 0.11461818181818181 0.10673348881059892\n",
      "Overlap train-valid: 0\n",
      "Overlap train-test: 0\n",
      "Overlap valid-test: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "y = df[\"label\"].astype(int)\n",
    "groups = df[\"person_id\"]\n",
    "\n",
    "gss1 = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=42)\n",
    "idx_trainval, idx_test = next(gss1.split(df, y, groups=groups))\n",
    "\n",
    "df_trainval = df.iloc[idx_trainval].copy()\n",
    "df_test = df.iloc[idx_test].copy()\n",
    "\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "idx_train, idx_valid = next(gss2.split(df_trainval, df_trainval[\"label\"].astype(int),\n",
    "                                       groups=df_trainval[\"person_id\"]))\n",
    "\n",
    "df_train = df_trainval.iloc[idx_train].copy()\n",
    "df_valid = df_trainval.iloc[idx_valid].copy()\n",
    "\n",
    "print(\"Train/Valid/Test:\", df_train.shape[0], df_valid.shape[0], df_test.shape[0])\n",
    "print(\"Prevalence train/valid/test:\",\n",
    "      float(df_train[\"label\"].mean()),\n",
    "      float(df_valid[\"label\"].mean()),\n",
    "      float(df_test[\"label\"].mean()))\n",
    "\n",
    "print(\"Overlap train-valid:\", len(set(df_train[\"person_id\"]) & set(df_valid[\"person_id\"])))\n",
    "print(\"Overlap train-test:\", len(set(df_train[\"person_id\"]) & set(df_test[\"person_id\"])))\n",
    "print(\"Overlap valid-test:\", len(set(df_valid[\"person_id\"]) & set(df_test[\"person_id\"])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699c524d-2ae5-4bac-8e4a-45ecc4066b9e",
   "metadata": {},
   "source": [
    "### Preprocess + model + Day-6 style cross-fitted Platt calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deeb6d72-1273-40ab-9096-00d5a90cffd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5 done. cal size=12198\n",
      "Fold 2/5 done. cal size=12198\n",
      "Fold 3/5 done. cal size=12198\n",
      "Fold 4/5 done. cal size=12197\n",
      "Fold 5/5 done. cal size=12197\n",
      "Done. Have p_test_raw and p_test_hat.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "id_cols = [\"encounter_id\", \"person_id\", \"label\"]\n",
    "feature_cols = [c for c in df.columns if c not in id_cols]\n",
    "\n",
    "numeric_cols = [\n",
    "    \"time_in_hospital\", \"num_lab_procedures\", \"num_procedures\", \"num_medications\",\n",
    "    \"number_outpatient\", \"number_emergency\", \"number_inpatient\"\n",
    "]\n",
    "categorical_cols = [c for c in feature_cols if c not in numeric_cols]\n",
    "\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train[\"label\"].astype(int).to_numpy()\n",
    "g_train = df_train[\"person_id\"].to_numpy()\n",
    "\n",
    "X_valid = df_valid[feature_cols]\n",
    "y_valid = df_valid[\"label\"].astype(int).to_numpy()\n",
    "\n",
    "X_test = df_test[feature_cols]\n",
    "y_test = df_test[\"label\"].astype(int).to_numpy()\n",
    "\n",
    "def make_dense_ohe():\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "prep_tree_dense = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([(\"impute\", SimpleImputer(strategy=\"median\"))]), numeric_cols),\n",
    "        (\"cat\", Pipeline([(\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                          (\"onehot\", make_dense_ohe())]), categorical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def make_base_model():\n",
    "    return Pipeline([\n",
    "        (\"prep\", prep_tree_dense),\n",
    "        (\"clf\", HistGradientBoostingClassifier(\n",
    "            max_depth=6,\n",
    "            learning_rate=0.05,\n",
    "            max_iter=400,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "def clip01(p, eps=1e-15):\n",
    "    p = np.asarray(p)\n",
    "    return np.clip(p, eps, 1 - eps)\n",
    "\n",
    "# --- OOF predictions on TRAIN (grouped) ---\n",
    "K = 5\n",
    "gkf = GroupKFold(n_splits=K)\n",
    "p_oof = np.zeros(len(df_train), dtype=float)\n",
    "\n",
    "for fold, (tr_idx, cal_idx) in enumerate(gkf.split(X_train, y_train, groups=g_train), start=1):\n",
    "    m = make_base_model()\n",
    "    m.fit(X_train.iloc[tr_idx], y_train[tr_idx])\n",
    "    p_oof[cal_idx] = m.predict_proba(X_train.iloc[cal_idx])[:, 1]\n",
    "    print(f\"Fold {fold}/{K} done. cal size={len(cal_idx)}\")\n",
    "\n",
    "# --- Platt scaling (sigmoid) on OOF predictions ---\n",
    "p_oof_c = clip01(p_oof)\n",
    "z_oof = np.log(p_oof_c / (1 - p_oof_c)).reshape(-1, 1)\n",
    "\n",
    "platt = LogisticRegression(solver=\"lbfgs\", C=1e6, max_iter=2000)\n",
    "platt.fit(z_oof, y_train)\n",
    "\n",
    "# --- Fit final model on full TRAIN ---\n",
    "final_model = make_base_model()\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "p_test_raw = final_model.predict_proba(X_test)[:, 1]\n",
    "z_test = np.log(clip01(p_test_raw) / (1 - clip01(p_test_raw))).reshape(-1, 1)\n",
    "p_test_hat = platt.predict_proba(z_test)[:, 1]\n",
    "\n",
    "print(\"Done. Have p_test_raw and p_test_hat.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb51878-fc80-4d61-ad24-0807a4436a8d",
   "metadata": {},
   "source": [
    "### Create a “scored table” + save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c3e1d6-363c-4ff8-9281-3901370f99e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\sarfo\\Dropbox\\Courses\\Data Science\\30-days-of-data-science\\Day-7\\reports\\DAY07_scored_test.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>person_id</th>\n",
       "      <th>label</th>\n",
       "      <th>p_raw</th>\n",
       "      <th>p_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67387</th>\n",
       "      <td>189144708</td>\n",
       "      <td>42941232</td>\n",
       "      <td>1</td>\n",
       "      <td>0.610624</td>\n",
       "      <td>0.612003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38644</th>\n",
       "      <td>120136542</td>\n",
       "      <td>23838849</td>\n",
       "      <td>1</td>\n",
       "      <td>0.556518</td>\n",
       "      <td>0.557934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87183</th>\n",
       "      <td>277879686</td>\n",
       "      <td>88227540</td>\n",
       "      <td>1</td>\n",
       "      <td>0.542616</td>\n",
       "      <td>0.544036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67883</th>\n",
       "      <td>190944528</td>\n",
       "      <td>57751650</td>\n",
       "      <td>0</td>\n",
       "      <td>0.517605</td>\n",
       "      <td>0.519027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42842</th>\n",
       "      <td>132138702</td>\n",
       "      <td>76743099</td>\n",
       "      <td>0</td>\n",
       "      <td>0.511674</td>\n",
       "      <td>0.513096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       encounter_id  person_id  label     p_raw     p_hat\n",
       "67387     189144708   42941232      1  0.610624  0.612003\n",
       "38644     120136542   23838849      1  0.556518  0.557934\n",
       "87183     277879686   88227540      1  0.542616  0.544036\n",
       "67883     190944528   57751650      0  0.517605  0.519027\n",
       "42842     132138702   76743099      0  0.511674  0.513096"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_test = df_test[[\"encounter_id\", \"person_id\", \"label\"]].copy()\n",
    "scored_test[\"p_raw\"] = p_test_raw\n",
    "scored_test[\"p_hat\"] = p_test_hat  # calibrated probability\n",
    "scored_test = scored_test.sort_values(\"p_hat\", ascending=False)\n",
    "\n",
    "reports_dir = project_root / \"Day-7\" / \"reports\"\n",
    "reports_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "scored_path = reports_dir / \"DAY07_scored_test.csv\"\n",
    "scored_test.to_csv(scored_path, index=False)\n",
    "\n",
    "print(\"Saved:\", scored_path)\n",
    "scored_test.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c2461-fbf2-43f1-b6cb-1c3048fea724",
   "metadata": {},
   "source": [
    "### Write the scored table into DuckDB (so it behaves like a warehouse “gold” output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93a4e5ea-2468-49d8-9873-9aa86e9a9a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB table created: gold_diabetes_scored_day7\n",
      "Rows: 20153\n"
     ]
    }
   ],
   "source": [
    "# Write to DuckDB as a new table (replace each time you run Day 7)\n",
    "con.execute(\"CREATE OR REPLACE TABLE gold_diabetes_scored_day7 AS SELECT * FROM scored_test\")\n",
    "\n",
    "print(\"DuckDB table created: gold_diabetes_scored_day7\")\n",
    "print(\"Rows:\", con.execute(\"SELECT COUNT(*) FROM gold_diabetes_scored_day7\").fetchone()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9300b5f-f58e-4360-aae9-4d20f513b18e",
   "metadata": {},
   "source": [
    "### Make the 4 evaluation plots and save them (PR, ROC, Calibration, Lift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6330ca0d-8da6-4924-b68f-22a99c114a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarfo\\AppData\\Local\\Temp\\ipykernel_55536\\1511125559.py:36: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  cal = df_cal.groupby(\"bin\").agg(mean_p=(\"p_hat\", \"mean\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plots into: C:\\Users\\sarfo\\Dropbox\\Courses\\Data Science\\30-days-of-data-science\\Day-7\\reports\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, average_precision_score, roc_auc_score\n",
    "\n",
    "y = scored_test[\"label\"].to_numpy()\n",
    "p = scored_test[\"p_hat\"].to_numpy()\n",
    "\n",
    "# --- PR curve ---\n",
    "prec, rec, _ = precision_recall_curve(y, p)\n",
    "ap = average_precision_score(y, p)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(rec, prec)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(f\"Precision–Recall Curve (AP={ap:.3f})\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / \"DAY07_pr_curve.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# --- ROC curve ---\n",
    "fpr, tpr, _ = roc_curve(y, p)\n",
    "auc = roc_auc_score(y, p)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(f\"ROC Curve (AUC={auc:.3f})\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / \"DAY07_roc_curve.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# --- Calibration (reliability) plot using deciles ---\n",
    "df_cal = scored_test.copy()\n",
    "df_cal[\"bin\"] = pd.qcut(df_cal[\"p_hat\"], q=10, duplicates=\"drop\")\n",
    "cal = df_cal.groupby(\"bin\").agg(mean_p=(\"p_hat\", \"mean\"),\n",
    "                                obs_rate=(\"label\", \"mean\"),\n",
    "                                n=(\"label\", \"size\")).reset_index()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(cal[\"mean_p\"], cal[\"obs_rate\"], marker=\"o\")\n",
    "plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "plt.xlabel(\"Mean predicted probability\")\n",
    "plt.ylabel(\"Observed event rate\")\n",
    "plt.title(\"Calibration Plot (Deciles)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / \"DAY07_calibration.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "# --- Lift / Gains: cumulative captured positives vs population fraction ---\n",
    "df_gain = scored_test.copy()\n",
    "df_gain[\"cum_pos\"] = df_gain[\"label\"].cumsum()\n",
    "total_pos = df_gain[\"label\"].sum()\n",
    "df_gain[\"cum_recall\"] = df_gain[\"cum_pos\"] / (total_pos if total_pos > 0 else 1)\n",
    "df_gain[\"pop_frac\"] = (np.arange(len(df_gain)) + 1) / len(df_gain)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df_gain[\"pop_frac\"], df_gain[\"cum_recall\"])\n",
    "plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "plt.xlabel(\"Fraction of population targeted\")\n",
    "plt.ylabel(\"Fraction of positives captured (recall)\")\n",
    "plt.title(\"Cumulative Gains (Lift) Curve\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(reports_dir / \"DAY07_gains_curve.png\", dpi=200)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved plots into:\", reports_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d8565b-38ea-42d1-8083-f1b2ce71a627",
   "metadata": {},
   "source": [
    "### Top-K table (what leadership actually understands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba712519-169a-4ac4-9ff6-940d39120337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_frac</th>\n",
       "      <th>k</th>\n",
       "      <th>captured</th>\n",
       "      <th>precision_at_k</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>201</td>\n",
       "      <td>73</td>\n",
       "      <td>0.363184</td>\n",
       "      <td>0.349429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>1007</td>\n",
       "      <td>304</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.231791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>2015</td>\n",
       "      <td>502</td>\n",
       "      <td>0.249132</td>\n",
       "      <td>0.190383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.20</td>\n",
       "      <td>4030</td>\n",
       "      <td>829</td>\n",
       "      <td>0.205707</td>\n",
       "      <td>0.143511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   top_frac     k  captured  precision_at_k  threshold\n",
       "0      0.01   201        73        0.363184   0.349429\n",
       "1      0.05  1007       304        0.301887   0.231791\n",
       "2      0.10  2015       502        0.249132   0.190383\n",
       "3      0.20  4030       829        0.205707   0.143511"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def topk_summary(y_true, p, frac):\n",
    "    y_true = np.asarray(y_true)\n",
    "    p = np.asarray(p)\n",
    "    n = len(y_true)\n",
    "    k = max(1, int(np.floor(frac*n)))\n",
    "    order = np.argsort(-p)\n",
    "    idx = order[:k]\n",
    "    return {\n",
    "        \"top_frac\": frac,\n",
    "        \"k\": k,\n",
    "        \"captured\": int(y_true[idx].sum()),\n",
    "        \"precision_at_k\": float(y_true[idx].mean()),\n",
    "        \"threshold\": float(np.quantile(p, 1-frac))\n",
    "    }\n",
    "\n",
    "rows = [topk_summary(y, p, f) for f in [0.01, 0.05, 0.10, 0.20]]\n",
    "topk_df = pd.DataFrame(rows)\n",
    "topk_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95e841d-03bd-4ee3-b26d-8237ed65d5ca",
   "metadata": {},
   "source": [
    "Save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1e3ef6e-485d-46e8-b20d-022fec900b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\sarfo\\Dropbox\\Courses\\Data Science\\30-days-of-data-science\\Day-7\\reports\\DAY07_topk_summary.csv\n"
     ]
    }
   ],
   "source": [
    "topk_df.to_csv(reports_dir / \"DAY07_topk_summary.csv\", index=False)\n",
    "print(\"Saved:\", reports_dir / \"DAY07_topk_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a99e5cb-0f5f-4c09-a4c8-e316113101db",
   "metadata": {},
   "source": [
    "### Write DAY07.md (a mini model card/report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6527c3a9-478e-42a7-af95-d70c897a60a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\sarfo\\Dropbox\\Courses\\Data Science\\30-days-of-data-science\\Day-7\\reports\\DAY07.md\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import brier_score_loss, log_loss\n",
    "\n",
    "p_clip = np.clip(p, 1e-15, 1-1e-15)\n",
    "\n",
    "report = f\"\"\"# Day 7 — Scoring output + Model report\n",
    "\n",
    "## What I produced\n",
    "- A scored test table with calibrated probabilities (p_hat)\n",
    "- A DuckDB gold-style scored table: gold_diabetes_scored_day7\n",
    "- Four standard evaluation plots: PR, ROC, Calibration, Gains (Lift)\n",
    "- A top-K summary table (capacity targeting)\n",
    "\n",
    "## Test-set metrics (calibrated probabilities)\n",
    "Prevalence: {y.mean():.6f}\n",
    "PR-AUC (Average Precision): {average_precision_score(y, p):.6f}\n",
    "ROC-AUC: {roc_auc_score(y, p):.6f}\n",
    "Brier score: {brier_score_loss(y, p):.6f}\n",
    "Log loss: {log_loss(y, p_clip, labels=[0,1]):.6f}\n",
    "\n",
    "## Files\n",
    "- DAY07_scored_test.csv\n",
    "- DAY07_topk_summary.csv\n",
    "- DAY07_pr_curve.png\n",
    "- DAY07_roc_curve.png\n",
    "- DAY07_calibration.png\n",
    "- DAY07_gains_curve.png\n",
    "\"\"\"\n",
    "\n",
    "md_path = reports_dir / \"DAY07.md\"\n",
    "md_path.write_text(report, encoding=\"utf-8\")\n",
    "print(\"Saved:\", md_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da06d9-bc6f-4413-967a-b0233d040c82",
   "metadata": {},
   "source": [
    "### Close DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d269beaa-33f5-459c-9cb7-6e5484ca9d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB closed.\n"
     ]
    }
   ],
   "source": [
    "con.close()\n",
    "print(\"DuckDB closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0f6b1a-d230-465e-8fd3-a9c6e742a78b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
