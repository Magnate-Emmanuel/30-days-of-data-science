{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c10af78a-a302-4566-8834-d8d9c6ae004f",
   "metadata": {},
   "source": [
    "### Setup + connect to DuckDB (robust paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27980f38-2279-4483-a657-3c6aa9bcb706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: C:\\Users\\sarfo\\Dropbox\\Courses\\Data Science\\30-days-of-data-science\n",
      "DB path: C:\\Users\\sarfo\\Dropbox\\Courses\\Data Science\\30-days-of-data-science\\Day-11\\data\\warehouse\\day11_noshow.duckdb\n",
      "Tables: ['bronze_appointments', 'gold_appointments_base', 'gold_appointments_features_v1', 'gold_appointments_features_v1_patient_split', 'silver_appointments', 'split_patient_v1']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "def find_repo_root(start=None):\n",
    "    p = (start or Path.cwd()).resolve()\n",
    "    while True:\n",
    "        if (p / \"Day-1\").exists():\n",
    "            return p\n",
    "        if p == p.parent:\n",
    "            raise FileNotFoundError(\"Could not find repo root (expected a Day-1 folder).\")\n",
    "        p = p.parent\n",
    "\n",
    "repo = find_repo_root()\n",
    "print(\"Repo root:\", repo)\n",
    "\n",
    "db_candidates = [\n",
    "    repo / \"Day-13\" / \"data\" / \"warehouse\" / \"day13_noshow.duckdb\",\n",
    "    repo / \"Day-11\" / \"data\" / \"warehouse\" / \"day11_noshow.duckdb\",\n",
    "]\n",
    "db_path = next((p for p in db_candidates if p.exists()), None)\n",
    "print(\"DB path:\", db_path)\n",
    "if db_path is None:\n",
    "    raise FileNotFoundError(\"Could not find Day-13 or Day-11 noshow DuckDB.\")\n",
    "\n",
    "con = duckdb.connect(str(db_path))\n",
    "print(\"Tables:\", [t[0] for t in con.execute(\"SHOW TABLES\").fetchall()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc30c4ad-e051-453d-866d-aad8e4b76fc5",
   "metadata": {},
   "source": [
    "### Load the feature contract (from Day 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bafe37a2-2973-46ad-9c6e-73141e2d1980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contract: C:\\Users\\sarfo\\Dropbox\\Courses\\Data Science\\30-days-of-data-science\\Day-13\\artifacts\\noshow_feature_contract_v1.json\n",
      "n_features: 19\n",
      "numeric: 16 categorical: 3\n",
      "label_col: label | treatment_col: sms_received\n"
     ]
    }
   ],
   "source": [
    "contract_candidates = [\n",
    "    repo / \"Day-13\" / \"artifacts\" / \"noshow_feature_contract_v1.json\",\n",
    "    repo / \"Day-13\" / \"artifacts\" / \"noshow_feature_contract_v2.json\",\n",
    "]\n",
    "contract_path = next((p for p in contract_candidates if p.exists()), None)\n",
    "print(\"Contract:\", contract_path)\n",
    "if contract_path is None:\n",
    "    raise FileNotFoundError(\"Could not find noshow feature contract in Day-13/artifacts.\")\n",
    "\n",
    "contract = json.loads(Path(contract_path).read_text(encoding=\"utf-8\"))\n",
    "\n",
    "id_cols = contract[\"id_cols\"]\n",
    "label_col = contract[\"label_col\"]\n",
    "treat_col = contract[\"treatment_col\"]\n",
    "feature_cols = contract[\"feature_cols\"]\n",
    "numeric_cols = contract[\"numeric_cols\"]\n",
    "categorical_cols = contract[\"categorical_cols\"]\n",
    "\n",
    "print(\"n_features:\", len(feature_cols))\n",
    "print(\"numeric:\", len(numeric_cols), \"categorical:\", len(categorical_cols))\n",
    "print(\"label_col:\", label_col, \"| treatment_col:\", treat_col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4467747c-d4a1-43a7-89c2-80f86bbc7990",
   "metadata": {},
   "source": [
    "### Load gold + splits into pandas (train/valid/test)\n",
    "\n",
    "You created the view on Day 14: gold_appointments_features_v1_patient_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8288122-d89f-418c-af74-791f4b2b2d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 110516\n",
      "split\n",
      "train    77368\n",
      "valid    16649\n",
      "test     16499\n",
      "Name: count, dtype: int64\n",
      "Prevalence overall: 0.20188027073003004\n"
     ]
    }
   ],
   "source": [
    "view_name = \"gold_appointments_features_v1_patient_split\"\n",
    "\n",
    "df = con.execute(f\"\"\"\n",
    "SELECT {\", \".join(id_cols)}, {label_col}, {treat_col}, split,\n",
    "       {\", \".join(feature_cols)}\n",
    "FROM {view_name}\n",
    "\"\"\").df()\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "print(df[\"split\"].value_counts())\n",
    "print(\"Prevalence overall:\", df[label_col].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c9b325-fb9c-4bdf-9734-f03b48673f1a",
   "metadata": {},
   "source": [
    "### Build X/y per split (and confirm no leakage columns)\n",
    "\n",
    "We do not include sms_received in the predictive feature set, because tomorrow you’ll be deciding who gets SMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73775e67-7e72-4431-b9d8-0fd1f3e0595e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 77368 prev: 0.20301675111157066\n",
      "Valid rows: 16649 prev: 0.20349570544777465\n",
      "Test rows : 16499 prev: 0.19492090429723014\n"
     ]
    }
   ],
   "source": [
    "df_train = df[df[\"split\"]==\"train\"].copy()\n",
    "df_valid = df[df[\"split\"]==\"valid\"].copy()\n",
    "df_test  = df[df[\"split\"]==\"test\"].copy()\n",
    "\n",
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train[label_col].astype(int)\n",
    "\n",
    "X_valid = df_valid[feature_cols]\n",
    "y_valid = df_valid[label_col].astype(int)\n",
    "\n",
    "X_test  = df_test[feature_cols]\n",
    "y_test  = df_test[label_col].astype(int)\n",
    "\n",
    "print(\"Train rows:\", len(X_train), \"prev:\", y_train.mean())\n",
    "print(\"Valid rows:\", len(X_valid), \"prev:\", y_valid.mean())\n",
    "print(\"Test rows :\", len(X_test),  \"prev:\", y_test.mean())\n",
    "\n",
    "# quick leakage sanity: treatment should NOT be in feature_cols\n",
    "assert treat_col not in feature_cols, \"treatment_col is in feature_cols — remove it from the contract.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee891e4a-def3-4245-930a-c3603ffbd81a",
   "metadata": {},
   "source": [
    "### Preprocessing (sparse for logistic, dense for HistGB)\n",
    "\n",
    "HistGradientBoosting needs dense input, so we’ll define a dense preprocessor for tree models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9589d9ae-cca2-4f66-a559-1c7a16992ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Logistic: allow sparse\n",
    "prep_linear = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scale\", StandardScaler(with_mean=False)),  # OK for sparse pipelines\n",
    "        ]), numeric_cols),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),  # sparse by default\n",
    "        ]), categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# Trees (dense): force dense one-hot (float32 helps memory)\n",
    "prep_tree_dense = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([\n",
    "            (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "        ]), numeric_cols),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, dtype=np.float32)),\n",
    "        ]), categorical_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7762e68b-950a-4b77-a7ac-89b7331b009c",
   "metadata": {},
   "source": [
    "### Models (baseline leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9252f47-3fba-4ef1-b7dd-c352c1db76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "\n",
    "models = {\n",
    "    \"logreg\": Pipeline([\n",
    "        (\"prep\", prep_linear),\n",
    "        (\"clf\", LogisticRegression(max_iter=3000, solver=\"lbfgs\"))\n",
    "    ]),\n",
    "    \"tree\": Pipeline([\n",
    "        (\"prep\", prep_tree_dense),\n",
    "        (\"clf\", DecisionTreeClassifier(max_depth=6, min_samples_leaf=200, random_state=42))\n",
    "    ]),\n",
    "    \"rf\": Pipeline([\n",
    "        (\"prep\", prep_tree_dense),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            n_estimators=400, min_samples_leaf=50, n_jobs=-1, random_state=42\n",
    "        ))\n",
    "    ]),\n",
    "    \"hist_gb\": Pipeline([\n",
    "        (\"prep\", prep_tree_dense),\n",
    "        (\"clf\", HistGradientBoostingClassifier(\n",
    "            max_depth=6, learning_rate=0.05, max_iter=400, random_state=42\n",
    "        ))\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36740939-f2ce-4ca0-a15f-9aeee351aacf",
   "metadata": {},
   "source": [
    "### Metrics + Top-K targeting function (safe logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f64deba-6f1d-45db-b3d3-698dbf3a5b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score, brier_score_loss, log_loss\n",
    "\n",
    "def compute_metrics(y_true, p):\n",
    "    y_true = np.asarray(y_true)\n",
    "    p = np.asarray(p)\n",
    "    p_clip = np.clip(p, 1e-15, 1-1e-15)\n",
    "    return {\n",
    "        \"prevalence\": float(y_true.mean()),\n",
    "        \"mean_p\": float(p.mean()),\n",
    "        \"median_p\": float(np.median(p)),\n",
    "        \"pr_auc\": float(average_precision_score(y_true, p)),\n",
    "        \"roc_auc\": float(roc_auc_score(y_true, p)),\n",
    "        \"brier\": float(brier_score_loss(y_true, p)),\n",
    "        \"logloss\": float(log_loss(y_true, p_clip)),\n",
    "    }\n",
    "\n",
    "def topk_metrics(y_true, p, frac):\n",
    "    y_true = np.asarray(y_true)\n",
    "    p = np.asarray(p)\n",
    "    n = len(y_true)\n",
    "    k = max(1, int(frac * n))\n",
    "    idx = np.argsort(-p)[:k]\n",
    "    captured = int(y_true[idx].sum())\n",
    "    prec = float(captured / k)\n",
    "    thr = float(np.sort(p)[-k])\n",
    "    return {\"top_frac\": frac, \"k\": k, \"captured\": captured, \"precision_at_k\": prec, \"threshold\": thr}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ed935f-d0f6-4289-8f07-d35ec35c475b",
   "metadata": {},
   "source": [
    "### Fit all models, compare on VALID, then evaluate once on TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ed2c104-c27f-4227-a18a-ab43e5b40ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>valid_pr_auc</th>\n",
       "      <th>valid_brier</th>\n",
       "      <th>valid_logloss</th>\n",
       "      <th>valid_top10_precision</th>\n",
       "      <th>test_pr_auc</th>\n",
       "      <th>test_brier</th>\n",
       "      <th>test_logloss</th>\n",
       "      <th>test_top10_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hist_gb</td>\n",
       "      <td>0.371375</td>\n",
       "      <td>0.143703</td>\n",
       "      <td>0.439805</td>\n",
       "      <td>0.418870</td>\n",
       "      <td>0.359799</td>\n",
       "      <td>0.139529</td>\n",
       "      <td>0.429035</td>\n",
       "      <td>0.410552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.363924</td>\n",
       "      <td>0.144681</td>\n",
       "      <td>0.443200</td>\n",
       "      <td>0.405048</td>\n",
       "      <td>0.352447</td>\n",
       "      <td>0.140471</td>\n",
       "      <td>0.432553</td>\n",
       "      <td>0.398423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.335357</td>\n",
       "      <td>0.145812</td>\n",
       "      <td>0.446210</td>\n",
       "      <td>0.368990</td>\n",
       "      <td>0.324296</td>\n",
       "      <td>0.141487</td>\n",
       "      <td>0.434900</td>\n",
       "      <td>0.351122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.341447</td>\n",
       "      <td>0.146467</td>\n",
       "      <td>0.449605</td>\n",
       "      <td>0.378005</td>\n",
       "      <td>0.335375</td>\n",
       "      <td>0.141968</td>\n",
       "      <td>0.438471</td>\n",
       "      <td>0.378411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  valid_pr_auc  valid_brier  valid_logloss  valid_top10_precision  \\\n",
       "3  hist_gb      0.371375     0.143703       0.439805               0.418870   \n",
       "2       rf      0.363924     0.144681       0.443200               0.405048   \n",
       "1     tree      0.335357     0.145812       0.446210               0.368990   \n",
       "0   logreg      0.341447     0.146467       0.449605               0.378005   \n",
       "\n",
       "   test_pr_auc  test_brier  test_logloss  test_top10_precision  \n",
       "3     0.359799    0.139529      0.429035              0.410552  \n",
       "2     0.352447    0.140471      0.432553              0.398423  \n",
       "1     0.324296    0.141487      0.434900              0.351122  \n",
       "0     0.335375    0.141968      0.438471              0.378411  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leader = []\n",
    "top_fracs = [0.01, 0.05, 0.10, 0.20]\n",
    "\n",
    "for name, pipe in models.items():\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    p_valid = pipe.predict_proba(X_valid)[:, 1]\n",
    "    p_test  = pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    m_valid = compute_metrics(y_valid, p_valid)\n",
    "    m_test  = compute_metrics(y_test, p_test)\n",
    "\n",
    "    # one operational metric to compare quickly\n",
    "    t10_valid = topk_metrics(y_valid, p_valid, 0.10)[\"precision_at_k\"]\n",
    "    t10_test  = topk_metrics(y_test,  p_test,  0.10)[\"precision_at_k\"]\n",
    "\n",
    "    leader.append({\n",
    "        \"model\": name,\n",
    "        \"valid_pr_auc\": m_valid[\"pr_auc\"],\n",
    "        \"valid_brier\": m_valid[\"brier\"],\n",
    "        \"valid_logloss\": m_valid[\"logloss\"],\n",
    "        \"valid_top10_precision\": t10_valid,\n",
    "        \"test_pr_auc\": m_test[\"pr_auc\"],\n",
    "        \"test_brier\": m_test[\"brier\"],\n",
    "        \"test_logloss\": m_test[\"logloss\"],\n",
    "        \"test_top10_precision\": t10_test,\n",
    "    })\n",
    "\n",
    "leader_df = pd.DataFrame(leader).sort_values([\"valid_brier\",\"valid_pr_auc\"], ascending=[True, False])\n",
    "leader_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe61bc27-3c29-4ef8-9a2a-5cf3e9ea04c5",
   "metadata": {},
   "source": [
    "### Calibrate the best model with Platt scaling on VALID\n",
    "\n",
    "We avoid CalibratedClassifierCV(cv=\"prefit\") because your sklearn version rejects it. This Platt approach works everywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50bdd3c9-fa87-4d95-90ba-746ca54207e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST MODEL: hist_gb\n",
      "VALID (calibrated): {'prevalence': 0.20349570544777465, 'mean_p': 0.20356071860360694, 'median_p': 0.17965294343169308, 'pr_auc': 0.37137528441261786, 'roc_auc': 0.7368793740279505, 'brier': 0.1452222568330195, 'logloss': 0.44661341284334144}\n",
      "TEST  (calibrated): {'prevalence': 0.19492090429723014, 'mean_p': 0.20335601817356758, 'median_p': 0.1800428200244986, 'pr_auc': 0.3597989973811414, 'roc_auc': 0.7397114639480457, 'brier': 0.14084112620677178, 'logloss': 0.4358437775024725}\n",
      "TEST {'top_frac': 0.01, 'k': 164, 'captured': 85, 'precision_at_k': 0.5182926829268293, 'threshold': 0.6005846754320254}\n",
      "TEST {'top_frac': 0.05, 'k': 824, 'captured': 362, 'precision_at_k': 0.4393203883495146, 'threshold': 0.4507367716001566}\n",
      "TEST {'top_frac': 0.1, 'k': 1649, 'captured': 677, 'precision_at_k': 0.4105518496058217, 'threshold': 0.39323639605387173}\n",
      "TEST {'top_frac': 0.2, 'k': 3299, 'captured': 1220, 'precision_at_k': 0.36980903304031526, 'threshold': 0.31780418585262915}\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "best_name = leader_df.iloc[0][\"model\"]\n",
    "best_model = models[best_name]\n",
    "\n",
    "# Refit best model on TRAIN only (keeps VALID clean for calibration)\n",
    "best_model.fit(X_train, y_train)\n",
    "p_valid_raw = best_model.predict_proba(X_valid)[:, 1]\n",
    "p_test_raw  = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Platt scaling: fit logistic regression on raw probability as a single feature\n",
    "platt = LogisticRegression(max_iter=2000, solver=\"lbfgs\")\n",
    "platt.fit(p_valid_raw.reshape(-1, 1), y_valid)\n",
    "\n",
    "p_valid_hat = platt.predict_proba(p_valid_raw.reshape(-1, 1))[:, 1]\n",
    "p_test_hat  = platt.predict_proba(p_test_raw.reshape(-1, 1))[:, 1]\n",
    "\n",
    "print(\"BEST MODEL:\", best_name)\n",
    "print(\"VALID (calibrated):\", compute_metrics(y_valid, p_valid_hat))\n",
    "print(\"TEST  (calibrated):\", compute_metrics(y_test,  p_test_hat))\n",
    "\n",
    "for f in top_fracs:\n",
    "    print(\"TEST\", topk_metrics(y_test, p_test_hat, f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ed645f-cd67-4fda-b6e8-f6e7d261207d",
   "metadata": {},
   "source": [
    "### Save artifacts for Day 16–20 (model + calibrator + contract + metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d217664b-95cb-4961-b7b5-71b47d93f4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved base model -> C:\\Users\\sarfo\\Dropbox\\Courses\\Data Science\\30-days-of-data-science\\Day-15\\artifacts\\noshow_base_model.joblib\n",
      "Saved platt      -> C:\\Users\\sarfo\\Dropbox\\Courses\\Data Science\\30-days-of-data-science\\Day-15\\artifacts\\noshow_platt_calibrator.joblib\n",
      "Saved contract   -> C:\\Users\\sarfo\\Dropbox\\Courses\\Data Science\\30-days-of-data-science\\Day-15\\artifacts\\noshow_feature_contract.json\n",
      "Saved metrics    -> C:\\Users\\sarfo\\Dropbox\\Courses\\Data Science\\30-days-of-data-science\\Day-15\\reports\\day15_metrics.json\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "art_dir = repo / \"Day-15\" / \"artifacts\"\n",
    "rep_dir = repo / \"Day-15\" / \"reports\"\n",
    "art_dir.mkdir(parents=True, exist_ok=True)\n",
    "rep_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "base_model_path = art_dir / \"noshow_base_model.joblib\"\n",
    "platt_path = art_dir / \"noshow_platt_calibrator.joblib\"\n",
    "contract_copy_path = art_dir / \"noshow_feature_contract.json\"\n",
    "metrics_path = rep_dir / \"day15_metrics.json\"\n",
    "\n",
    "joblib.dump(best_model, base_model_path)\n",
    "joblib.dump(platt, platt_path)\n",
    "\n",
    "contract_copy_path.write_text(json.dumps(contract, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "summary = {\n",
    "    \"timestamp_local\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"db_path\": str(db_path),\n",
    "    \"view_used\": view_name,\n",
    "    \"best_model\": best_name,\n",
    "    \"leaderboard_valid_sorted\": leader_df.to_dict(orient=\"records\"),\n",
    "    \"valid_calibrated_metrics\": compute_metrics(y_valid, p_valid_hat),\n",
    "    \"test_calibrated_metrics\": compute_metrics(y_test, p_test_hat),\n",
    "    \"test_topk_calibrated\": [topk_metrics(y_test, p_test_hat, f) for f in top_fracs],\n",
    "}\n",
    "metrics_path.write_text(json.dumps(summary, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved base model ->\", base_model_path)\n",
    "print(\"Saved platt      ->\", platt_path)\n",
    "print(\"Saved contract   ->\", contract_copy_path)\n",
    "print(\"Saved metrics    ->\", metrics_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fedbe2-5559-4cfe-8785-0b823e75496e",
   "metadata": {},
   "source": [
    "### Create Day-15/DAY15.md (so Day 15 isn’t empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "199b405e-1848-42d7-bf48-d21c96a9aa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: C:\\Users\\sarfo\\Dropbox\\Courses\\Data Science\\30-days-of-data-science\\Day-15\\reports\\DAY15.md\n"
     ]
    }
   ],
   "source": [
    "md_path = repo / \"Day-15\" / \"reports\"/ \"DAY15.md\"\n",
    "md_path.write_text(\n",
    "f\"\"\"# Day 15 — Predictive no-show model + calibration\n",
    "\n",
    "Today I trained leakage-safe predictive baselines using the Day 14 patient split (no patient overlap across train/valid/test).\n",
    "\n",
    "I compared multiple models on VALID using probability quality metrics (Brier score / log loss) and ranking metrics (PR-AUC, ROC-AUC, top-K precision). I selected the best model by VALID Brier score and calibrated its probabilities using Platt scaling fit on the VALID set.\n",
    "\n",
    "Artifacts saved for later (Day 16–20):\n",
    "- `{base_model_path.relative_to(repo)}`\n",
    "- `{platt_path.relative_to(repo)}`\n",
    "- `{contract_copy_path.relative_to(repo)}`\n",
    "- `{metrics_path.relative_to(repo)}`\n",
    "\n",
    "Next: Day 16 begins causal work (propensity + ATE) using SMS_received as treatment.\n",
    "\"\"\",\n",
    "encoding=\"utf-8\")\n",
    "print(\"Wrote:\", md_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a4a85-28e0-4610-9c62-e828da6fa403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
